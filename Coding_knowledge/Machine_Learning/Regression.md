| 회귀 종류                              | 출력 데이터 형태           | 노이즈(오차) 분포 가정                  | 목적함수 / 손실함수                                                                      | 대표 적용 상황                         |
| ---------------------------------- | ------------------- | ------------------------------ | -------------------------------------------------------------------------------- | -------------------------------- |
| **Ordinary Least Squares (OLS)**   | 연속값 (real)          | **Gaussian** (정규분포)            | $\displaystyle \min_x \|A x - y\|_2^2$ (L2 손실)                                   | 일반적인 회귀 (선형 모델, 평균 예측)           |
| **Ridge Regression**               | 연속값                 | Gaussian + 정규화(regularization) | $\displaystyle \min_x \|A x - y\|_2^2 + \lambda \|x\|_2^2$                       | 다중공선성, 과적합 방지                    |
| **Lasso Regression**               | 연속값                 | Gaussian + sparsity prior      | $\displaystyle \min_x \|A x - y\|_2^2 + \lambda \|x\|_1$                         | 변수 선택(feature selection), 희소 모델  |
| **Elastic Net**                    | 연속값                 | Gaussian + 혼합 정규화              | $\displaystyle \min_x \|A x - y\|_2^2 + \lambda_1 \|x\|_1 + \lambda_2 \|x\|_2^2$ | Lasso와 Ridge 절충형                 |
| **Robust Regression (L1)**         | 연속값                 | **Laplace** (쌍지수 분포)           | $\displaystyle \min_x \|A x - y\|_1$                                             | 이상치(outlier)가 많은 데이터             |
| **Huber Regression**               | 연속값                 | Gaussian + 일부 이상치 완화           | Huber loss (L1+L2 혼합)                                                            | 소량의 이상치 존재 시                     |
| **Quantile Regression**            | 연속값                 | 비대칭 **Laplace** 분포             | Quantile loss                                                                    | 분위수(예: 중위수, 상위 90%) 예측           |
| **Logistic Regression**            | 0/1 (이진)            | **Bernoulli** 분포               | $\displaystyle -\sum_i \big[ y_i \log p_i + (1 - y_i)\log(1 - p_i) \big]$        | 이진 분류 문제 (yes/no, spam/not spam) |
| **Probit Regression**              | 0/1 (이진)            | **Gaussian CDF (probit)**      | $\displaystyle -\sum_i \log \Phi(y_i (a^T x + b))$                               | 로지스틱과 유사, 정규 CDF 사용              |
| **Poisson Regression**             | 비음수 정수 (count)      | **Poisson** 분포                 | $\displaystyle \min_x \, -\sum_i \big[y_i (a^T x) - e^{a^T x}\big]$              | 사건 수(count) 예측 (교통사고, 클릭 수 등)    |
| **Negative Binomial Regression**   | Count (과산포 데이터)     | Negative Binomial              | Poisson보다 분산 큰 count data                                                        | 과산포된 이벤트 데이터                     |
| **Multinomial Logistic (Softmax)** | 다중 클래스 (3+)         | Multinomial                    | Cross-entropy loss                                                               | 다중 분류 문제                         |
| **Ordinal Regression**             | 순서형 클래스 (예: 등급 1~5) | Ordered Logistic / Probit      | Ordered log-likelihood                                                           | 만족도, 등급 예측                       |
| **Tobit Regression**               | 절단된 연속값             | Gaussian (censored)            | Likelihood with truncation                                                       | 0 이하 관측 불가 데이터 (소득, 수요 등)        |
